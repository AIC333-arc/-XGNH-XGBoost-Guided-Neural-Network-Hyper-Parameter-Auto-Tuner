# -XNH-XGBoost-Neural-Network-Hyper-Parameter-Auto-Tuner
This is an XGBoost Neural Network Hyperparameter Auto Tuner to optimize the effectiveness of your neural networks.

I initially conceptualized the idea of stacking neural network architectures—one as the base neural network, and another as a hyperparameter tuner. Later, I realized that XGBoost, one of the top-performing ML models, could be combined effectively with a PyTorch neural network architecture for hyperparameter optimization.

This Auto XGBoost Hyperparameter Tuner was my original idea. While I used ChatGPT to generate the initial code, I meticulously reviewed and understood every line.

The tuner is highly adaptable and user-friendly—you can customize iterations, hyperparameters, activation functions, and more. The beauty of this project lies in its flexibility and ease of modification.
